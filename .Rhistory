params = params,
data = train_final,
label = train_labels,
nrounds = 30,
objective = 'binary:hinge',
verbose = 0)
predictions <- predict(xgb_fit_final, test_final)
test_error <- mean(predictions != test$y.yes)
importance_matrix <- xgb.importance(model = xgb_fit_final)
xgb.plot.importance(importance_matrix, top_n = 10, measure = "Gain")
bankData <-  read.csv('bank-additional-full.csv', sep = ';')
bankData <- bankData %>% drop_na()
bankData <- bankData %>% select(-c('duration'))
# Encode categorical variables as n-1 dummy variables
dummy <- dummyVars(" ~ job + marital + education + default + housing + loan + contact + month + poutcome + y + day_of_week ", data = bankData)
dummy_pred = data.frame(predict(dummy, newdata = bankData))
bankData = cbind(bankData %>% select(-c('job', "marital" , "education" , "default" , "housing" , "loan" , "contact" , "month" , "poutcome", 'day_of_week')), dummy_pred)
# Encode our target variable y as a binary variable that takes on a value of 0 when the target is 'no', and 1 when the target is 'yes
bankData$y.yes = (bankData$y.no * -1) + 1
bankData <- bankData %>% select(-c(y, y.no, pdays))
# Set seed for reproducibility
set.seed(1)
# Split the data into test and train sets, with 1/2 of all observations in the training set and half the observations in the test test
train_index <- sample(1:nrow(bankData), nrow(bankData)/2)
train <- bankData[train_index,]
test <- bankData[-train_index,]
# Generate the train and test labels for the response variable
train_labels = train$y.yes
test_labels = test$y.yes
# Convert matrix into a sparse matrix that can be used with xgboost
train_final <- Matrix:: sparse.model.matrix(y.yes~.-1,data = train)
test_final <- Matrix:: sparse.model.matrix(y.yes~.-1,data = test)
# Create grid of hyperparameters that need to be tuned
hyperparameter_grid <- expand.grid(
eta = c(0.001, 0.01, 0.1,0.2),
max_depth = c(1,2,3,4),
subsample = c(.65, .8, 1),
optimal_trees = 0,
min_error = 0
)
# Create a for loop to iterate over hyperparameter grid and fit different models, then populate optimal trees and min error columns of
# hyperparameter grid. Early stopping is set to 10, which means if there is no improvement to error after 10 iterations the optimization stops
for(i in 1:nrow(hyperparameter_grid)) {
# create parameter list
params <- list(
eta = hyperparameter_grid$eta[i],
max_depth = hyperparameter_grid$max_depth[i],
subsample = hyperparameter_grid$subsample[i]
)
set.seed(1)
# train model
xgb_tune <- xgb.cv(
params = params,
data = train_final,
label = train_labels,
nrounds = 5000,
nfold = 5,
objective = "binary:hinge",
verbose = 0,
early_stopping_rounds = 10
)
# add min training error and optimal number of trees to the hyperparameter grid dataframe, test error corresponds to validation error
hyperparameter_grid$optimal_trees[i] <- which.min(xgb_tune$evaluation_log$test_error_mean)
hyperparameter_grid$min_error[i] <- min(xgb_tune$evaluation_log$test_error_mean)
}
# Sort hyperparameter grid by test error to find the optimal selection of hyperparameters
hyperparameter_grid %>% arrange(min_error)
# Fit the model corresponding to tuned hyperparameters
# Generate params list corresponding to optimal hyperparameters
params <- list(eta = 0.1, max_depth = 4, subsample = 0.65)
xgb_fit_final <- xgboost(
params = params,
data = train_final,
label = train_labels,
nrounds = 67,
objective = 'binary:hinge',
verbose = 0)
# Find the test error rate of the chosen model
predictions <- predict(xgb_fit_final, test_final)
test_error <- mean(predictions != test$y.yes)
# Plot a graph showing variable importance
importance_matrix <- xgb.importance(model = xgb_fit_final)
xgb.plot.importance(importance_matrix, top_n = 10, measure = "Gain")
importance_matrix <- xgb.importance(model = xgb_fit_final)
xgb.plot.importance(importance_matrix, top_n = 10, measure = "Gain") +ggtitle('Importance Plot where duration is excluded')
?xgb.plot.importance
xgb.plot.importance(importance_matrix, top_n = 10, measure = "Gain", main = 'Importance Plot when duration is Excluded')
xgb.plot.importance(importance_matrix, top_n = 10, measure = "Gain", main = 'Importance Plot when duration is Excluded', cex = 0.5)
xgb.plot.importance(importance_matrix, top_n = 10, measure = "Gain", main = 'Importance Plot when duration is Excluded')
xgb.plot.importance(importance_matrix, top_n = 10, measure = "Gain", main = 'Importance Plot when duration is Excluded', cex.main = 0.5)
xgb.plot.importance(importance_matrix, top_n = 10, measure = "Gain", main = 'Importance Plot when duration is Excluded', cex.main = 0.8)
xgb.plot.importance(importance_matrix, top_n = 10, measure = "Gain", main = 'Importance Plot when duration is Excluded', cex.main = 0.7)
xgb.plot.importance(importance_matrix, top_n = 10, measure = "Gain", main = 'Importance Plot when duration is Excluded', cex.main = 0.6)
xgb.plot.importance(importance_matrix, top_n = 10, measure = "Gain", main = 'Importance Plot when duration is Excluded', cex.main = 0.5)
xgb.plot.importance(importance_matrix, top_n = 10, measure = "Gain", main = 'Importance Plot when Duration is Excluded', cex.main = 0.5)
# Now consider the model where the feature 'duration' is included
bankData <- bankData <-  read.csv('bank-additional-full.csv', sep = ';')
# Encode categorical variables as n-1 dummy variables
dummy <- dummyVars(" ~ job + marital + education + default + housing + loan + contact + month + poutcome + y + day_of_week ", data = bankData)
dummy_pred = data.frame(predict(dummy, newdata = bankData))
bankData = cbind(bankData %>% select(-c('job', "marital" , "education" , "default" , "housing" , "loan" , "contact" , "month" , "poutcome", 'day_of_week')), dummy_pred)
# Encode our target variable y as a binary variable that takes on a value of 0 when the target is 'no', and 1 when the target is 'yes
bankData$y.yes = (bankData$y.no * -1) + 1
bankData <- bankData %>% select(-c(y, y.no, pdays))
# Set seed for reproducibility
set.seed(1)
# Split the data into test and train sets, with 1/2 of all observations in the training set and half the observations in the test test
train_index <- sample(1:nrow(bankData), nrow(bankData)/2)
train_with_dur <- bankData[train_index,]
test_with_dur <- bankData[-train_index,]
# Generate the train and test labels for the response variable
train_labels = train$y.yes
test_labels = test$y.yes
# Convert matrix into a sparse matrix that can be used with xgboost
train_dur_final <- Matrix:: sparse.model.matrix(y.yes~.-1,data = train)
test_dur_final <- Matrix:: sparse.model.matrix(y.yes~.-1,data = test)
# Use same hyperparameter grid as before
hyperparameter_grid <- expand.grid(
eta = c(0.001, 0.01, 0.1,0.2),
max_depth = c(1,2,3,4),
subsample = c(.65, .8, 1),
optimal_trees = 0,
min_error = 0
)
# Create a for loop to iterate over hyperparameter grid and fit different models, then populate optimal trees and min error columns of
# hyperparameter grid. Early stopping is set to 10, which means if there is no improvement to error after 10 iterations the optimization stops
for(i in 1:nrow(hyperparameter_grid)) {
# create parameter list
params <- list(
eta = hyperparameter_grid$eta[i],
max_depth = hyperparameter_grid$max_depth[i],
subsample = hyperparameter_grid$subsample[i]
)
set.seed(1)
# train model
xgb_tune <- xgb.cv(
params = params,
data = train_final,
label = train_labels,
nrounds = 5000,
nfold = 5,
objective = "binary:hinge",
verbose = 0,
early_stopping_rounds = 10
)
# add min training error and optimal number of trees to the hyperparameter grid dataframe, test error corresponds to validation error
hyperparameter_grid$optimal_trees[i] <- which.min(xgb_tune$evaluation_log$test_error_mean)
hyperparameter_grid$min_error[i] <- min(xgb_tune$evaluation_log$test_error_mean)
}
# Sort hyperparameter grid by validation error to find the optimal selection of hyperparameters
hyperparameter_grid %>% arrange(min_error)
bankData <- bankData <-  read.csv('bank-additional-full.csv', sep = ';')
# Encode categorical variables as n-1 dummy variables
dummy <- dummyVars(" ~ job + marital + education + default + housing + loan + contact + month + poutcome + y + day_of_week ", data = bankData)
dummy_pred = data.frame(predict(dummy, newdata = bankData))
bankData = cbind(bankData %>% select(-c('job', "marital" , "education" , "default" , "housing" , "loan" , "contact" , "month" , "poutcome", 'day_of_week')), dummy_pred)
# Encode our target variable y as a binary variable that takes on a value of 0 when the target is 'no', and 1 when the target is 'yes
bankData$y.yes = (bankData$y.no * -1) + 1
bankData <- bankData %>% select(-c(y, y.no, pdays))
# Set seed for reproducibility
set.seed(1)
# Split the data into test and train sets, with 1/2 of all observations in the training set and half the observations in the test test
train_index <- sample(1:nrow(bankData), nrow(bankData)/2)
train_with_dur <- bankData[train_index,]
test_with_dur <- bankData[-train_index,]
train_labels = train$y.yes
test_labels = test$y.yes
train_labels = train_with_dur$y.yes
test_labels = test_with_dur$y.yes
train_dur_final <- Matrix:: sparse.model.matrix(y.yes~.-1,data = train)
test_dur_final <- Matrix:: sparse.model.matrix(y.yes~.-1,data = test)
bankData <- bankData <-  read.csv('bank-additional-full.csv', sep = ';')
# Encode categorical variables as n-1 dummy variables
dummy <- dummyVars(" ~ job + marital + education + default + housing + loan + contact + month + poutcome + y + day_of_week ", data = bankData)
dummy_pred = data.frame(predict(dummy, newdata = bankData))
bankData = cbind(bankData %>% select(-c('job', "marital" , "education" , "default" , "housing" , "loan" , "contact" , "month" , "poutcome", 'day_of_week')), dummy_pred)
# Encode our target variable y as a binary variable that takes on a value of 0 when the target is 'no', and 1 when the target is 'yes
bankData$y.yes = (bankData$y.no * -1) + 1
bankData <- bankData %>% select(-c(y, y.no, pdays))
# Set seed for reproducibility
set.seed(1)
# Split the data into test and train sets, with 1/2 of all observations in the training set and half the observations in the test test
train_index <- sample(1:nrow(bankData), nrow(bankData)/2)
train_with_dur <- bankData[train_index,]
test_with_dur <- bankData[-train_index,]
# Generate the train and test labels for the response variable
train_labels = train_with_dur$y.yes
test_labels = test_with_dur$y.yes
# Convert matrix into a sparse matrix that can be used with xgboost
train_dur_final <- Matrix:: sparse.model.matrix(y.yes~.-1,data = train)
test_dur_final <- Matrix:: sparse.model.matrix(y.yes~.-1,data = test)
train_dur_final <- Matrix:: sparse.model.matrix(y.yes~.-1,data = train_with_dur)
test_dur_final <- Matrix:: sparse.model.matrix(y.yes~.-1,data = test_with_dur)
hyperparameter_grid <- expand.grid(
eta = c(0.001, 0.01, 0.1,0.2),
max_depth = c(1,2,3,4),
subsample = c(.65, .8, 1),
optimal_trees = 0,
min_error = 0
)
for(i in 1:nrow(hyperparameter_grid)) {
# create parameter list
params <- list(
eta = hyperparameter_grid$eta[i],
max_depth = hyperparameter_grid$max_depth[i],
subsample = hyperparameter_grid$subsample[i]
)
set.seed(1)
# train model
xgb_tune <- xgb.cv(
params = params,
data = train_final,
label = train_labels,
nrounds = 5000,
nfold = 5,
objective = "binary:hinge",
verbose = 0,
early_stopping_rounds = 10
)
# add min training error and optimal number of trees to the hyperparameter grid dataframe, test error corresponds to validation error
hyperparameter_grid$optimal_trees[i] <- which.min(xgb_tune$evaluation_log$test_error_mean)
hyperparameter_grid$min_error[i] <- min(xgb_tune$evaluation_log$test_error_mean)
}
# Sort hyperparameter grid by validation error to find the optimal selection of hyperparameters
hyperparameter_grid %>% arrange(min_error)
for(i in 1:nrow(hyperparameter_grid)) {
# create parameter list
params <- list(
eta = hyperparameter_grid$eta[i],
max_depth = hyperparameter_grid$max_depth[i],
subsample = hyperparameter_grid$subsample[i]
)
set.seed(1)
# train model
xgb_tune <- xgb.cv(
params = params,
data = train_dur_final,
label = train_labels,
nrounds = 5000,
nfold = 5,
objective = "binary:hinge",
verbose = 0,
early_stopping_rounds = 10
)
# add min training error and optimal number of trees to the hyperparameter grid dataframe, test error corresponds to validation error
hyperparameter_grid$optimal_trees[i] <- which.min(xgb_tune$evaluation_log$test_error_mean)
hyperparameter_grid$min_error[i] <- min(xgb_tune$evaluation_log$test_error_mean)
}
hyperparameter_grid %>% arrange(min_error)
xgb_fit_final_dur <- xgboost(
params = params,
data = train_final,
label = train_labels,
nrounds = 66,
objective = 'binary:hinge',
verbose = 0)
xgb_fit_final_dur <- xgboost(
params = params,
data = train_dur_final,
label = train_labels,
nrounds = 66,
objective = 'binary:hinge',
verbose = 0)
predictions <- predict(xgb_fit_final, test_final)
test_error <- mean(predictions != test$y.yes)
predictions <- predict(xgb_fit_final, test_final)
test_error <- mean(predictions != test_with_dur$y.yes)
predictions <- predict(xgb_fit_final, test_with_dur)
test_error <- mean(predictions != test_with_dur$y.yes)
predictions <- predict(xgb_fit_final_dur, test_with_dur)
test_error <- mean(predictions != test_with_dur$y.yes)
predictions <- predict(xgb_fit_final_dur, test_with_dur)
xgb_fit_final_dur <- xgboost(
params = params,
data = train_dur_final,
label = train_labels,
nrounds = 66,
objective = 'binary:hinge',
verbose = 0)
predictions <- predict(xgb_fit_final_dur, test_with_dur)
predictions <- predict(xgb_fit_final, test_dur_final)
predictions <- predict(xgb_fit_final_dur, test_dur_final)
test_error <- mean(predictions != test_with_dur$y.yes)
importance_matrix <- xgb.importance(model = xgb_fit_final_dur)
xgb.plot.importance(importance_matrix, top_n = 10, measure = "Gain")
xgb.plot.importance(importance_matrix, top_n = 10, measure = "Gain", main = 'Importance Plot with Duration Included', cex.main = 0.5)
bankData <- bankData <-  read.csv('bank-additional-full.csv', sep = ';')
bankData <- bankData %>% drop_na()
bankData <- bankData %>% select(-c('duration', 'emp.var.rate', 'cons.price.idx', 'cons.conf.idx', 'euribor3m', 'nr.employed'))
# Encode categorical variables as n-1 dummy variables
dummy <- dummyVars(" ~ job + marital + education + default + housing + loan + contact + month + poutcome + y + day_of_week ", data = bankData)
dummy_pred = data.frame(predict(dummy, newdata = bankData))
bankData = cbind(bankData %>% select(-c('job', "marital" , "education" , "default" , "housing" , "loan" , "contact" , "month" , "poutcome", 'day_of_week')), dummy_pred)
# Encode our target variable y as a binary variable that takes on a value of 0 when the target is 'no', and 1 when the target is 'yes
bankData$y.yes = (bankData$y.no * -1) + 1
bankData <- bankData %>% select(-c(y, y.no, pdays))
# Set seed for reproducibility
set.seed(1)
# Split the data into test and train sets, with 1/2 of all observations in the training set and half the observations in the test test
train_index <- sample(1:nrow(bankData), nrow(bankData)/2)
train <- bankData[train_index,]
test <- bankData[-train_index,]
# Generate the train and test labels for the response variable
train_labels = train$y.yes
test_labels = test$y.yes
# Convert matrix into a sparse matrix that can be used with xgboost
train_final <- Matrix:: sparse.model.matrix(y.yes~.-1,data = train)
test_final <- Matrix:: sparse.model.matrix(y.yes~.-1,data = test)
# Create grid of hyperparameters that need to be tuned
hyperparameter_grid <- expand.grid(
eta = c(0.001, 0.01, 0.1,0.2),
max_depth = c(1,2,3,4),
subsample = c(.65, .8, 1),
optimal_trees = 0,
min_error = 0
)
# Create a for loop to iterate over hyperparameter grid and fit different models, then populate optimal trees and min error columns of
# hyperparameter grid. Early stopping is set to 10, which means if there is no improvement to error after 10 iterations the optimization stops
for(i in 1:nrow(hyperparameter_grid)) {
# create parameter list
params <- list(
eta = hyperparameter_grid$eta[i],
max_depth = hyperparameter_grid$max_depth[i],
subsample = hyperparameter_grid$subsample[i]
)
set.seed(1)
# train model
xgb_tune <- xgb.cv(
params = params,
data = train_final,
label = train_labels,
nrounds = 5000,
nfold = 5,
objective = "binary:hinge",
verbose = 0,
early_stopping_rounds = 10
)
# add min training error and optimal number of trees to the hyperparameter grid dataframe, test error corresponds to validation error
hyperparameter_grid$optimal_trees[i] <- which.min(xgb_tune$evaluation_log$test_error_mean)
hyperparameter_grid$min_error[i] <- min(xgb_tune$evaluation_log$test_error_mean)
}
# Sort hyperparameter grid by validation error to find the optimal selection of hyperparameters
hyperparameter_grid %>% arrange(min_error)
# Fit the model corresponding to tuned hyperparameters
# Generate params list corresponding to optimal hyperparameters
params <- list(eta = 0.2, max_depth = 4, subsample = 0.8)
xgb_fit_final <- xgboost(
params = params,
data = train_final,
label = train_labels,
nrounds = 30,
objective = 'binary:hinge',
verbose = 0)
# Find the test error rate of the chosen model
predictions <- predict(xgb_fit_final, test_final)
test_error <- mean(predictions != test$y.yes)
# Plot a graph showing variable importance
importance_matrix <- xgb.importance(model = xgb_fit_final)
xgb.plot.importance(importance_matrix, top_n = 10, measure = "Gain")
xgb.plot.importance(importance_matrix, top_n = 10, measure = "Gain", main = 'Importance Plot with Duration and Macro Variables Excluded', cex.main = 0.6)
xgb.plot.importance(importance_matrix, top_n = 10, measure = "Gain", main = 'Importance Plot with Duration and Macro Variables Excluded', cex.main = 0.5)
xgb.plot.importance(importance_matrix, top_n = 10, measure = "Gain", main = 'Importance Plot with no Duration and Macro Vars', cex.main = 0.5)
bankData <-  read.csv('bank-additional-full.csv', sep = ';')
bankData <- bankData %>% drop_na()
bankData <- bankData %>% select(-c('duration'))
# Encode categorical variables as n-1 dummy variables
dummy <- dummyVars(" ~ job + marital + education + default + housing + loan + contact + month + poutcome + y + day_of_week ", data = bankData)
dummy_pred = data.frame(predict(dummy, newdata = bankData))
bankData = cbind(bankData %>% select(-c('job', "marital" , "education" , "default" , "housing" , "loan" , "contact" , "month" , "poutcome", 'day_of_week')), dummy_pred)
# Encode our target variable y as a binary variable that takes on a value of 0 when the target is 'no', and 1 when the target is 'yes
bankData$y.yes = (bankData$y.no * -1) + 1
bankData <- bankData %>% select(-c(y, y.no, pdays))
# Set seed for reproducibility
set.seed(1)
# Split the data into test and train sets, with 1/2 of all observations in the training set and half the observations in the test test
train_index <- sample(1:nrow(bankData), nrow(bankData)/2)
train <- bankData[train_index,]
test <- bankData[-train_index,]
# Generate the train and test labels for the response variable
train_labels = train$y.yes
test_labels = test$y.yes
# Convert matrix into a sparse matrix that can be used with xgboost
train_final <- Matrix:: sparse.model.matrix(y.yes~.-1,data = train)
test_final <- Matrix:: sparse.model.matrix(y.yes~.-1,data = test)
# Create grid of hyperparameters that need to be tuned
hyperparameter_grid <- expand.grid(
eta = c(0.001, 0.01, 0.1,0.2),
max_depth = c(1,2,3,4),
subsample = c(.65, .8, 1),
optimal_trees = 0,
min_error = 0
)
# Create a for loop to iterate over hyperparameter grid and fit different models, then populate optimal trees and min error columns of
# hyperparameter grid. Early stopping is set to 10, which means if there is no improvement to error after 10 iterations the optimization stops
for(i in 1:nrow(hyperparameter_grid)) {
# create parameter list
params <- list(
eta = hyperparameter_grid$eta[i],
max_depth = hyperparameter_grid$max_depth[i],
subsample = hyperparameter_grid$subsample[i]
)
set.seed(1)
# train model
xgb_tune <- xgb.cv(
params = params,
data = train_final,
label = train_labels,
nrounds = 5000,
nfold = 5,
objective = "binary:hinge",
verbose = 0,
early_stopping_rounds = 10
)
# add min training error and optimal number of trees to the hyperparameter grid dataframe, test error corresponds to validation error
hyperparameter_grid$optimal_trees[i] <- which.min(xgb_tune$evaluation_log$test_error_mean)
hyperparameter_grid$min_error[i] <- min(xgb_tune$evaluation_log$test_error_mean)
}
# Sort hyperparameter grid by test error to find the optimal selection of hyperparameters
hyperparameter_grid %>% arrange(min_error)
# Fit the model corresponding to tuned hyperparameters
# Generate params list corresponding to optimal hyperparameters
params <- list(eta = 0.1, max_depth = 4, subsample = 0.65)
xgb_fit_final <- xgboost(
params = params,
data = train_final,
label = train_labels,
nrounds = 67,
objective = 'binary:hinge',
verbose = 0)
# Find the test error rate of the chosen model
predictions <- predict(xgb_fit_final, test_final)
test_error <- mean(predictions != test$y.yes)
# Plot a graph showing variable importance
importance_matrix <- xgb.importance(model = xgb_fit_final)
xgb.plot.importance(importance_matrix, top_n = 10, measure = "Gain", main = 'Importance Plot when Duration is Excluded', cex.main = 0.5)
library(tinytex)
setwd('C:/Users/abugh/Documents/R/Machine Learning Project/BankData')
# Load in data
# For the model without the feature duration
bankData <-  read.csv('bank-additional-full.csv', sep = ';')
bankData <- bankData %>% drop_na()
bankData <- bankData %>% select(-c('duration'))
# Encode categorical variables as n-1 dummy variables
dummy <- dummyVars(" ~ job + marital + education + default + housing + loan + contact + month + poutcome + y + day_of_week ", data = bankData)
dummy_pred = data.frame(predict(dummy, newdata = bankData))
bankData = cbind(bankData %>% select(-c('job', "marital" , "education" , "default" , "housing" , "loan" , "contact" , "month" , "poutcome", 'day_of_week')), dummy_pred)
# Encode our target variable y as a binary variable that takes on a value of 0 when the target is 'no', and 1 when the target is 'yes
bankData$y.yes = (bankData$y.no * -1) + 1
bankData <- bankData %>% select(-c(y, y.no, pdays))
# Set seed for reproducibility
set.seed(1)
# Split the data into test and train sets, with 1/2 of all observations in the training set and half the observations in the test test
train_index <- sample(1:nrow(bankData), nrow(bankData)/2)
train <- bankData[train_index,]
test <- bankData[-train_index,]
# Generate the train and test labels for the response variable
train_labels = train$y.yes
test_labels = test$y.yes
# Convert matrix into a sparse matrix that can be used with xgboost
train_final <- Matrix:: sparse.model.matrix(y.yes~.-1,data = train)
test_final <- Matrix:: sparse.model.matrix(y.yes~.-1,data = test)
# Create grid of hyperparameters that need to be tuned
hyperparameter_grid <- expand.grid(
eta = c(0.001, 0.01, 0.1,0.2),
max_depth = c(1,2,3,4),
subsample = c(.65, .8, 1),
optimal_trees = 0,
min_error = 0
)
# Create a for loop to iterate over hyperparameter grid and fit different models, then populate optimal trees and min error columns of
# hyperparameter grid. Early stopping is set to 10, which means if there is no improvement to error after 10 iterations the optimization stops
for(i in 1:nrow(hyperparameter_grid)) {
# create parameter list
params <- list(
eta = hyperparameter_grid$eta[i],
max_depth = hyperparameter_grid$max_depth[i],
subsample = hyperparameter_grid$subsample[i]
)
set.seed(1)
# train model
xgb_tune <- xgb.cv(
params = params,
data = train_final,
label = train_labels,
nrounds = 5000,
nfold = 5,
objective = "binary:hinge",
verbose = 0,
early_stopping_rounds = 10
)
# add min training error and optimal number of trees to the hyperparameter grid dataframe, test error corresponds to validation error
hyperparameter_grid$optimal_trees[i] <- which.min(xgb_tune$evaluation_log$test_error_mean)
hyperparameter_grid$min_error[i] <- min(xgb_tune$evaluation_log$test_error_mean)
}
# Sort hyperparameter grid by test error to find the optimal selection of hyperparameters
hyperparameter_grid %>% arrange(min_error)
# Fit the model corresponding to tuned hyperparameters
# Generate params list corresponding to optimal hyperparameters
params <- list(eta = 0.1, max_depth = 4, subsample = 0.65)
xgb_fit_final <- xgboost(
params = params,
data = train_final,
label = train_labels,
nrounds = 67,
objective = 'binary:hinge',
verbose = 0)
# Find the test error rate of the chosen model
predictions <- predict(xgb_fit_final, test_final)
test_error <- mean(predictions != test$y.yes)
# Plot a graph showing variable importance
importance_matrix <- xgb.importance(model = xgb_fit_final)
xgb.plot.importance(importance_matrix, top_n = 10, measure = "Gain", main = 'Importance Plot when Duration is Excluded', cex.main = 0.5)
